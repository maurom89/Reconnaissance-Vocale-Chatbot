# -------------------------------
# Import libraries
# -------------------------------
import streamlit as st
from groq import Groq
import json
import speech_recognition as sr
from gtts import gTTS
import os

# -------------------------------
# Streamlit Page Configuration
# -------------------------------
st.set_page_config(
    page_title="AI Voice Assistant",
    page_icon="ðŸŽ¤",
    layout="wide"
)

# -------------------------------
# Initialize Groq Client
# -------------------------------
client = Groq(api_key=)  # <<< CHANGE THIS

# -------------------------------
# Memory
# -------------------------------
if "messages" not in st.session_state:
    st.session_state.messages = []

# -------------------------------
# Get AI Response
# -------------------------------
def get_ai_response(user_message):
    response = client.chat.completions.create(
        model="llama-3.1-8b-instant",
        messages=[
            {"role": "system", "content": "You are a helpful AI assistant."},
            {"role": "user", "content": user_message}
        ]
    )
    return response.choices[0].message.content

# -------------------------------
# Clear Chat
# -------------------------------
def clear_chat():
    st.session_state.messages = []
    st.rerun()

# -------------------------------
# Download Chat
# -------------------------------
def download_chat():
    if st.session_state.messages:
        return json.dumps(st.session_state.messages, indent=2)
    return None

# -------------------------------
# TTS â€“ Make AI Speak
# -------------------------------
def speak_text(text):
    try:
        audio_path = os.path.join(os.getcwd(), "ai_voice.mp3")
        tts = gTTS(text=text, lang="fr")
        tts.save(audio_path)
        return audio_path
    except Exception as e:
        st.error(f"Erreur TTS : {e}")
        return None

# -------------------------------
# Voice Recording (Your Working Code)
# -------------------------------
def record_voice():
    recognizer = sr.Recognizer()
    microphone = sr.Microphone()

    recognizer.energy_threshold = 300
    recognizer.dynamic_energy_threshold = True
    recognizer.pause_threshold = 1.5

    try:
        with microphone as source:
            st.info("ðŸŽ¤ Ã‰coute en cours... Parlez maintenant.")
            recognizer.adjust_for_ambient_noise(source, duration=0.5)
            audio = recognizer.listen(source, timeout=5, phrase_time_limit=15)
            st.info("ðŸ”„ Traitement de votre voix...")

            text = recognizer.recognize_google(audio, language="fr-FR")
            st.success(f"ðŸ—£ï¸ Vous avez dit : {text}")
            return text

    except sr.WaitTimeoutError:
        st.error("â° Aucun son dÃ©tectÃ©.")
    except sr.UnknownValueError:
        st.error("â“ Impossible de comprendre l'audio.")
    except sr.RequestError:
        st.error("ðŸŒ ProblÃ¨me Internet pour la transcription.")
    except Exception as e:
        st.error(f"âš ï¸ Erreur : {e}")

    return None

# -------------------------------
# UI Header
# -------------------------------
st.title("ðŸ¤– Assistant Vocal IA")
st.write("Parlez ou Ã©crivez... Je rÃ©ponds aussi avec une voix humaine ðŸ”Š")

# -------------------------------
# Sidebar
# -------------------------------
with st.sidebar:
    st.header("ðŸ“– Instructions")
    st.markdown("""
    **Deux faÃ§ons d'utiliser l'assistant :**

    - ðŸ“ Tapez un message
    - ðŸŽ¤ Cliquez sur le bouton micro et parlez

    **Conseils Micro :**
    - Parlez clairement
    - Soyez proche du micro
    - Attendez les messages "Ã‰coute" / "Traitement"
    """)

# -------------------------------
# Model Info
# -------------------------------
with st.expander("â„¹ï¸ ModÃ¨le utilisÃ©", expanded=True):
    st.markdown("""
    **LLaMA 3.1 â€“ 8B Instant**
    
    - IA rapide et efficace  
    - ComprÃ©hension du franÃ§ais  
    - Parfait pour conversation  
    """)

# -------------------------------
# Buttons (Clear / Download)
# -------------------------------
col1, col2, col3 = st.columns([1, 1, 2])

with col1:
    if st.button("ðŸ—‘ï¸ Effacer"):
        clear_chat()

with col2:
    data = download_chat()
    if data:
        st.download_button(
            label="ðŸ“¥ TÃ©lÃ©charger",
            data=data,
            file_name="chat.json",
            mime="application/json"
        )

# -------------------------------
# Display Chat History
# -------------------------------
for message in st.session_state.messages:
    st.chat_message(message["role"]).write(message["content"])

# -------------------------------
# VOICE INPUT SECTION
# -------------------------------
col_input, col_voice = st.columns([4, 1])

with col_voice:
    use_voice = st.button("ðŸŽ¤ Micro", use_container_width=True)

if use_voice:
    spoken = record_voice()

    if spoken:
        # Add user message
        st.session_state.messages.append({"role": "user", "content": spoken})
        st.chat_message("user").write(spoken)

        # AI thinking
        with st.spinner("ðŸ¤” RÃ©flexion..."):
            reply = get_ai_response(spoken)

        # Add AI reply
        st.session_state.messages.append({"role": "assistant", "content": reply})
        st.chat_message("assistant").write(reply)

        # SPEAK AI REPLY ðŸ”Š
        audio_file = speak_text(reply)
        if audio_file:
            st.audio(audio_file, format="audio/mp3")

        st.rerun()

# -------------------------------
# TEXT INPUT SECTION
# -------------------------------
if prompt := st.chat_input("Ã‰crivez ici..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    st.chat_message("user").write(prompt)

    with st.spinner("ðŸ¤” RÃ©flexion..."):
        reply = get_ai_response(prompt)

    st.session_state.messages.append({"role": "assistant", "content": reply})
    st.chat_message("assistant").write(reply)

    # SPEAK AI REPLY ðŸ”Š
    audio_file = speak_text(reply)
    if audio_file:
        st.audio(audio_file, format="audio/mp3")